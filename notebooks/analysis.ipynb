{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8a0ac-a7c8-4947-9fcb-58186cd4c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telco Customer Churn Analysis\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this analysis, I'll explore the Telco Customer Churn dataset to gain insights into customer behavior and identify factors that influence customer churn. The dataset contains information about customer attributes, services they've signed up for, and whether they have churned or not.\n",
    "\n",
    "### Data Loading and Exploration\n",
    "\n",
    "Let's start by loading the dataset and exploring its contents.\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Telco_Customer_Churn\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "Data preprocessing is an essential step in any data analysis project. I handle missing values, encode categorical variables, and perform any necessary data transformations.\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Check for duplicates and remove them\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert Totalcharges column to numeric (if not already)\n",
    "data['Totalcharges'] = pd.to_numeric(data['Totalcharges'], errors='coerce')\n",
    "\n",
    "# Remove customer ID column (not useful for prediction)\n",
    "data.drop('Customerid', axis=1, inplace=True)\n",
    "\n",
    "## Insight: I found 11 missing values in the \"Totalcharges\" column. We need to decide how to handle these missing values.\n",
    "\n",
    "# Handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer instance\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Define columns with missing values\n",
    "columns_with_missing = [\"Totalcharges\"]\n",
    "\n",
    "# Apply the imputer to fill missing values\n",
    "data[columns_with_missing] = imputer.fit_transform(data[columns_with_missing])\n",
    "\n",
    "# Define the list of columns to be one-hot encoded\n",
    "columns_to_encode = ['Gender', 'Partner', 'Dependents', 'Phoneservice', 'Multiplelines', \n",
    "                     'Internetservice', 'Onlinesecurity', 'Onlinebackup', 'Deviceprotection', \n",
    "                     'Techsupport', 'Streamingtv', 'Streamingmovies', 'Contract', 'Paperlessbilling', 'Paymentmethod']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=columns_to_encode)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "data_encoded = data_encoded.drop(columns=columns_to_encode)\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "print(data_encoded.head())\n",
    "\n",
    "# Scale numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data[['Tenure', 'Monthlycharges', 'Totalcharges']] = scaler.fit_transform(data[['Tenure', 'Monthlycharges', 'Totalcharges']])\n",
    "\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Performed exploratory data analysis to better understand our data and identify patterns.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Telco_Customer_Churn.csv\")\n",
    "\n",
    "# Distribution of customer churn\n",
    "sns.countplot(data=data, x='Churn')\n",
    "plt.title(\"Distribution of Customer Churn\")\n",
    "plt.show()\n",
    "\n",
    "## Insight: I observed that there's an imbalance in the dataset, with more non-churned customers compared to churned customers. This is important to keep in mind during model evaluation.##\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Telco_Customer_Churn.csv\")\n",
    "\n",
    "# Select only the numeric columns for the correlation matrix\n",
    "numeric_columns = data.select_dtypes(include='number')\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = numeric_columns.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "## Insight: I observe some correlations between numerical variables. For example, there is a positive correlation between \"Monthlycharges\" and \"Totalcharges.\"##\n",
    "\n",
    "### Model Building\n",
    "\n",
    "Now, l built and trained a predictive model to predict customer churn.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(\"Churn\", axis=1)\n",
    "y = data[\"Churn\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the model evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Confusion Matrix:\\n{confusion}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "\n",
    "## Insight: An accuracy of 0.79 indicates that the model correctly predicted 79% of the instances in the dataset.\n",
    "\n",
    "### Interpretation and Action\n",
    "\n",
    "From the model, we can interpret the feature importance to identify which features are most influential in predicting customer churn. This knowledge can help in taking proactive measures to reduce churn, such as improving customer service or targeted marketing.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(features, feature_importance)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "## Insight: Totalcharges has the highest importance score, followed by Monthlycharges, which suggests that these factors strongly influence customer churn.##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
